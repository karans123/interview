https://engineering.linkedin.com/distributed-systems/log-what-every-software-engineer-should-know-about-real-time-datas-unifying


http://kafka.apache.org/documentation.html#introduction

https://www.quora.com/Whats-the-best-way-to-start-learning-Kafka

code - base
http://kafka.apache.org/082/javadoc/org/apache/kafka/



kafka(Messaging) -> storm(real time processing ) ->spark (next level MAP-Reduce )->Cassandra/HBASE(database)




how to setup kafka 



kafka  
http://redrockdigimark.com/apachemirror/kafka/0.10.1.1/kafka_2.11-0.10.1.1.tgz

zookeeper 
http://redrockdigimark.com/apachemirror/zookeeper/stable/zookeeper-3.4.9.tar.gz

Added 30 GB SSD for kafka and zookeeper data
disk mode is set to LVM to increase the space 

    [root@ip-172-31-13-39 opt]# pvcreate /dev/xvdf
      Physical volume "/dev/sdf" successfully created
    [root@ip-172-31-13-39 opt]# vgcreate vg1 /dev/xvdf 
      Volume group "vg1" successfully created
    [root@ip-172-31-13-39 opt]#  lvcreate -n lv1 -l 100%FREE vg1
      Logical volume "lv1" created.
    [root@ip-172-31-13-39 opt]# mkfs -t ext4 /dev/vg1/lv1
    mke2fs 1.42.12 (29-Aug-2014)
    Creating filesystem with 7863296 4k blocks and 1966080 inodes
    Filesystem UUID: b371ed33-911d-4164-af26-6948c5d419fc
    Superblock backups stored on blocks: 
    32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208, 
    4096000
    
    Allocating group tables: done                            
    Writing inode tables: done                            
    Creating journal (32768 blocks): done
    Writing superblocks and filesystem accounting information: done   
    
    [root@ip-172-31-13-39 opt]# echo "/dev/vg1/lv1 /mnt ext4 defaults  0 0" >> /etc/fstab
    [root@ip-172-31-13-39 opt]# mount -a 
    [root@ip-172-31-13-39 opt]# 

Installation

    
    [root@ip-172-31-9-49 opt]# wget http://redrockdigimark.com/apachemirror/kafka/0.10.1.1/kafka_2.11-0.10.1.1.tgz
    --2017-02-08 11:22:29--  http://redrockdigimark.com/apachemirror/kafka/0.10.1.1/kafka_2.11-0.10.1.1.tgz
    Resolving redrockdigimark.com (redrockdigimark.com)... 119.18.61.94
    Connecting to redrockdigimark.com (redrockdigimark.com)|119.18.61.94|:80... connected.
    HTTP request sent, awaiting response... 200 OK
    Length: 34424602 (33M) [application/x-tar]
    Saving to: ‘kafka_2.11-0.10.1.1.tgz’
    
    kafka_2.11-0.10.1.1 100%[===================>]  32.83M  1.14MB/s    in 20s     
    
    [root@ip-172-31-9-49 opt]# wget http://redrockdigimark.com/apachemirror/zookeeper/stable/zookeeper-3.4.9.tar.gz
    --2017-02-08 11:28:42--  http://redrockdigimark.com/apachemirror/zookeeper/stable/zookeeper-3.4.9.tar.gz
    Resolving redrockdigimark.com (redrockdigimark.com)... 119.18.61.94
    Connecting to redrockdigimark.com (redrockdigimark.com)|119.18.61.94|:80... connected.
    HTTP request sent, awaiting response... 200 OK
    Length: 22724574 (22M) [application/x-gzip]
    Saving to: ‘zookeeper-3.4.9.tar.gz’
    
    zookeeper-3.4.9.tar 100%[===================>]  21.67M  2.38MB/s    in 9.7s    
    
    2017-02-08 11:28:52 (2.24 MB/s) - ‘zookeeper-3.4.9.tar.gz’ saved [22724574/22724574]
    [root@ip-172-31-9-49 opt]# gunzip kafka_2.11-0.10.1.1.tgz 
    [root@ip-172-31-9-49 opt]# gunzip zookeeper-3.4.9.tar.gz 
    [root@ip-172-31-9-49 opt]# ls
    aws  kafka_2.11-0.10.1.1.tar  zookeeper-3.4.9.tar
    [root@ip-172-31-9-49 opt]# tar -xvf zookeeper-3.4.9.tar 
    
    [root@ip-172-31-9-49 opt]# tar -xvf  kafka_2.11-0.10.1.1.tar 
    [root@ip-172-31-9-49 opt]# mv kafka_2.11-0.10.1.1 kafka
    [root@ip-172-31-9-49 opt]# mv zookeeper-3.4.9 zookeeper
    [root@ip-172-31-9-49 conf]# cd /opt/zookeeper/conf/
    [root@ip-172-31-9-49 conf]# cp zoo_sample.cfg zoo.cfg
    #Zookeeper configuration
    [root@ip-172-31-9-49 conf]# vim zoo.cfg
    and change the dataDir variable
    dataDir=/mnt/zookeeper
    and added below config
    server.1=prod-scm-zookeeper-01.lenskart.internal:2888:3888
    server.2=prod-scm-zookeeper-02.lenskart.internal:2888:3888
    server.3=prod-scm-zookeeper-03.lenskart.internal:2888:3888
    //save and quit 
    and then insert unique id's into this file on all machines
    echo "1" > /mnt/zookeeper/myid
    
    //Kafka configuration 
    //change log directory 
    
    [root@ip-172-31-9-49 config]# vim  /opt/kafka/config/server.properties
    log.dirs=/mnt/kafka-logs
    //This needs to be changed for all the nodes
    broker.id=0
    //Make sure you replace the [BROKER_ID] with a unique number on each of the kafk
         nodes.
    zookeeper.connect=prod-scm-zookeeper-01.lenskart.internal,prod-scm-zookeeper-02.lenskart.internal,prod-scm-zookeeper-03.lenskart.internal


then start zookeeper 

    zookeeper/bin/zkServer.sh start 

then start kafka 

     kafka/bin/kafka-server-start.sh kafka/config/server.properties &
     disown

